{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Training\n",
    "\n",
    "Uses the Trainer included in Hugging Face `transformers` (backed by `accelerate`) since it mitigates a lot of annoying boilerplate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import Trainer, TrainingArguments, ModernBertConfig, AutoModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (242_552, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tconst</th><th>averageRating</th><th>json</th></tr><tr><td>str</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>&quot;tt0173052&quot;</td><td>4.1</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;The Prince and t…</td></tr><tr><td>&quot;tt0266288&quot;</td><td>7.4</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Azhakiya Ravanan…</td></tr><tr><td>&quot;tt6263490&quot;</td><td>4.3</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Getaway&quot;,\n",
       "&nbsp;&nbsp;&quot;gen…</td></tr><tr><td>&quot;tt10049110&quot;</td><td>7.8</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Die Wiese&quot;,\n",
       "&nbsp;&nbsp;&quot;g…</td></tr><tr><td>&quot;tt5761612&quot;</td><td>3.8</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Woman on the Edg…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;tt0079376&quot;</td><td>6.2</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;The Proud Twins&quot;…</td></tr><tr><td>&quot;tt1161064&quot;</td><td>3.2</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Super Capers: Th…</td></tr><tr><td>&quot;tt0179526&quot;</td><td>5.7</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Who&#x27;s the Caboos…</td></tr><tr><td>&quot;tt0188233&quot;</td><td>5.7</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;That&#x27;s Erotic&quot;,\n",
       "…</td></tr><tr><td>&quot;tt0082518&quot;</td><td>5.8</td><td>&quot;{\n",
       "&nbsp;&nbsp;&quot;title&quot;: &quot;Hoge hakken, ech…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (242_552, 3)\n",
       "┌────────────┬───────────────┬───────────────────────────────┐\n",
       "│ tconst     ┆ averageRating ┆ json                          │\n",
       "│ ---        ┆ ---           ┆ ---                           │\n",
       "│ str        ┆ f32           ┆ str                           │\n",
       "╞════════════╪═══════════════╪═══════════════════════════════╡\n",
       "│ tt0173052  ┆ 4.1           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"The Prince and t… │\n",
       "│ tt0266288  ┆ 7.4           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Azhakiya Ravanan… │\n",
       "│ tt6263490  ┆ 4.3           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Getaway\",         │\n",
       "│            ┆               ┆   \"gen…                       │\n",
       "│ tt10049110 ┆ 7.8           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Die Wiese\",       │\n",
       "│            ┆               ┆   \"g…                         │\n",
       "│ tt5761612  ┆ 3.8           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Woman on the Edg… │\n",
       "│ …          ┆ …             ┆ …                             │\n",
       "│ tt0079376  ┆ 6.2           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"The Proud Twins\"… │\n",
       "│ tt1161064  ┆ 3.2           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Super Capers: Th… │\n",
       "│ tt0179526  ┆ 5.7           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Who's the Caboos… │\n",
       "│ tt0188233  ┆ 5.7           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"That's Erotic\",   │\n",
       "│            ┆               ┆ …                             │\n",
       "│ tt0082518  ┆ 5.8           ┆ {                             │\n",
       "│            ┆               ┆   \"title\": \"Hoge hakken, ech… │\n",
       "└────────────┴───────────────┴───────────────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    pl.scan_parquet(\n",
    "        \"movie_data_plus_embeds_all.parquet\",\n",
    "    )\n",
    "    .select([\"tconst\", \"averageRating\", \"json\"])\n",
    "    .with_columns(averageRating=pl.col(\"averageRating\").cast(pl.Float32))\n",
    "    .collect()\n",
    "    .sample(fraction=1.0, shuffle=True, seed=42)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Custom Tokenizer\n",
    "\n",
    "Use the `modernbert` tokenizer as a base, just reduce the vocabulary significantly and tailor it to this specific dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'South': 17967, 'Ġgestation': 34422, 'Ġrelevant': 4623, 'Ġcron': 42695, 'Ġweaker': 21076, 'occ': 34\n",
      "378\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "json_docs = df[\"json\"].to_list()\n",
    "\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "print(str(base_tokenizer.vocab)[0:100])\n",
    "print(len(base_tokenizer(json_docs[0])[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "{'Brendan': 3660, 'gu': 752, 'Ir': 1595, 'ĠRuiz': 3764, 'Ã¼ller': 3184, 'Martin': 958, 'Adri': 2039,\n",
      "302\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "\n",
    "# don't train on all texts because it will take forever\n",
    "tokenizer = base_tokenizer.train_new_from_iterator(\n",
    "    iter(json_docs[:50000]), vocab_size=vocab_size,\n",
    "    # new_special_tokens=[\"  \", \"    \", \"      \"]\n",
    ")\n",
    "\n",
    "print(str(tokenizer.vocab)[0:100])\n",
    "print(len(tokenizer(json_docs[0])[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preencode all the tokens. A `max_length` of 1024 may be excessive but does not cause a proportionate reduction in model training speed over a 512 max length due to ModernBERT's unpadding + RoPE.\n",
    "\n",
    "In order to avoid OOMs on the host system, generate in batches, then push to the GPU. (ideally we _could_ push to the GPU for each batch but that will cause GPU memory leaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [03:23,  1.71s/it]                         \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([242552, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 1024\n",
    "token_batch_size = 2048\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# input_ids = torch.empty((0, max_length)).to(\"cpu\")\n",
    "# attention_mask = torch.empty((0, max_length)).to(\"cpu\")\n",
    "\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for docs in tqdm(batch(json_docs, token_batch_size), total=len(json_docs) // token_batch_size):\n",
    "    tokens = tokenizer(docs,\n",
    "                       max_length=max_length,\n",
    "                       padding=\"max_length\",\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\").to(\"cpu\")\n",
    "    \n",
    "    # input_ids = torch.vstack([input_ids, tokens[\"input_ids\"]])\n",
    "    # attention_mask = torch.vstack([attention_mask, tokens[\"attention_mask\"]])\n",
    "    \n",
    "    input_ids.append(tokens[\"input_ids\"])\n",
    "    attention_mask.append(tokens[\"attention_mask\"])\n",
    "   \n",
    "input_ids = torch.vstack(input_ids).to(device)\n",
    "attention_mask = torch.vstack(attention_mask).to(device)\n",
    "\n",
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1000, 7.4000, 4.3000,  ..., 6.4000, 6.0000, 6.5000], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "n_test = 20000\n",
    "\n",
    "X_input_ids_train = input_ids[:-n_test].int().to(device)\n",
    "X_input_ids_test = input_ids[-n_test:].int().to(device)\n",
    "\n",
    "X_attention_train = attention_mask[:-n_test].int().to(device)\n",
    "X_attention_test = attention_mask[-n_test:].int().to(device)\n",
    "\n",
    "y_train = torch.from_numpy(df[:-n_test][\"averageRating\"].to_numpy().copy()).to(device)\n",
    "y_test = torch.from_numpy(df[-n_test:][\"averageRating\"].to_numpy().copy()).to(device)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_input_ids_train, X_attention_train, y_train)\n",
    "test_dataset = TensorDataset(X_input_ids_test, X_attention_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "Due to the new tokenizer, the special tokens for the fresh ModernBERT model have to be explicitly defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': 2,\n",
       " 'sep_token': 4,\n",
       " 'pad_token': 5,\n",
       " 'cls_token': 3,\n",
       " 'mask_token': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_token_dict = dict(\n",
    "    zip(tokenizer.special_tokens_map.keys(), tokenizer.all_special_ids)\n",
    ")\n",
    "special_token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "dropout = 0.1\n",
    "\n",
    "config = ModernBertConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    max_position_embeddings=max_length,\n",
    "    hidden_size=hidden_size,\n",
    "    intermediate_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=8,\n",
    "    # global_attn_every_n_layers=2,\n",
    "    local_attention=16,\n",
    "    attention_dropout=dropout,\n",
    "    # embeddings_dropout=dropout,\n",
    "    # mlp_dropout=dropout,\n",
    "    unk_token_id=special_token_dict[\"unk_token\"],\n",
    "    sep_token_id=special_token_dict[\"sep_token\"],\n",
    "    pad_token_id=special_token_dict[\"pad_token\"],\n",
    "    cls_token_id=special_token_dict[\"cls_token\"],\n",
    "    mask_token_id=special_token_dict[\"mask_token\"],\n",
    ")\n",
    "\n",
    "transformer_model = AutoModel.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RatingsModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.transformer_model = model\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, targets=None):\n",
    "        x = self.transformer_model.forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        x = x.last_hidden_state[:, 0]  # the [CLS] vector\n",
    "\n",
    "        return self.output(x).squeeze()  # return 1D output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4968705\n"
     ]
    }
   ],
   "source": [
    "model = RatingsModel(transformer_model)\n",
    "_ = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)\n",
    "\n",
    "torch.set_float32_matmul_precision('high')  # perf increase for ModernBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss doesn't play nice with the `Trainer` out of the boss, so need [some tweaks](https://discuss.huggingface.co/t/no-log-for-validation-loss-during-training-with-trainer/40094/3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    input_ids = torch.stack([f[0] for f in examples])\n",
    "    attention_masks = torch.stack([f[1] for f in examples])\n",
    "    targets = torch.stack([f[2] for f in examples])\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"targets\": targets,\n",
    "    }\n",
    "\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=0):\n",
    "        outputs = model(**inputs)\n",
    "        # loss = nn.L1Loss()(outputs, inputs[\"targets\"])  # L1 loss is MAE\n",
    "        loss = nn.MSELoss()(outputs, inputs[\"targets\"])\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.001,\n",
    "    save_strategy=\"no\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.05,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=0.05,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,  # since data is in memory, as problem is GPU bound\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_persistent_workers=False,\n",
    ")\n",
    "\n",
    "# reinstantiate a clean model\n",
    "transformer_model = AutoModel.from_config(config)\n",
    "model = RatingsModel(transformer_model)\n",
    "_ = model.to(device)\n",
    "\n",
    "trainer = RegressionTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "trainer.can_return_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17390' max='17390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17390/17390 33:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.511300</td>\n",
       "      <td>1.173166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>1.160800</td>\n",
       "      <td>1.088658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>1.090700</td>\n",
       "      <td>1.074188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>1.090800</td>\n",
       "      <td>1.047315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>1.022600</td>\n",
       "      <td>1.043286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5220</td>\n",
       "      <td>1.015800</td>\n",
       "      <td>1.051057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6090</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>1.046057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6960</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>1.025580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7830</td>\n",
       "      <td>0.863300</td>\n",
       "      <td>1.047111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.884500</td>\n",
       "      <td>1.027024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9570</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>1.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10440</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>1.053287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>0.731600</td>\n",
       "      <td>1.091306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12180</td>\n",
       "      <td>0.732900</td>\n",
       "      <td>1.103272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13050</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>1.135734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13920</td>\n",
       "      <td>0.679900</td>\n",
       "      <td>1.118866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14790</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>1.145908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15660</td>\n",
       "      <td>0.638600</td>\n",
       "      <td>1.145411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16530</td>\n",
       "      <td>0.621900</td>\n",
       "      <td>1.153060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17390, training_loss=0.8742096105205938, metrics={'train_runtime': 2009.5099, 'train_samples_per_second': 1107.494, 'train_steps_per_second': 8.654, 'total_flos': 0.0, 'train_loss': 0.8742096105205938, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 1.5113,\n",
       "  'grad_norm': 10.823572158813477,\n",
       "  'learning_rate': 0.00019878432868078476,\n",
       "  'epoch': 0.5002875215641173,\n",
       "  'step': 870},\n",
       " {'eval_loss': 1.1731656789779663,\n",
       "  'eval_runtime': 5.6989,\n",
       "  'eval_samples_per_second': 3509.442,\n",
       "  'eval_steps_per_second': 27.549,\n",
       "  'epoch': 0.5002875215641173,\n",
       "  'step': 870},\n",
       " {'loss': 1.1608,\n",
       "  'grad_norm': 3.601486921310425,\n",
       "  'learning_rate': 0.00019513352557918312,\n",
       "  'epoch': 1.0005750431282345,\n",
       "  'step': 1740},\n",
       " {'eval_loss': 1.0886578559875488,\n",
       "  'eval_runtime': 5.673,\n",
       "  'eval_samples_per_second': 3525.466,\n",
       "  'eval_steps_per_second': 27.675,\n",
       "  'epoch': 1.0005750431282345,\n",
       "  'step': 1740}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = trainer.state.log_history\n",
    "\n",
    "logs[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (19, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>loss</th><th>grad_norm</th><th>learning_rate</th><th>epoch</th><th>step</th><th>eval_loss</th><th>eval_runtime</th><th>eval_samples_per_second</th><th>eval_steps_per_second</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.5113</td><td>10.823572</td><td>0.000199</td><td>0.500288</td><td>870</td><td>1.173166</td><td>5.6989</td><td>3509.442</td><td>27.549</td></tr><tr><td>1.1608</td><td>3.601487</td><td>0.000195</td><td>1.000575</td><td>1740</td><td>1.088658</td><td>5.673</td><td>3525.466</td><td>27.675</td></tr><tr><td>1.0907</td><td>2.74441</td><td>0.000189</td><td>1.500863</td><td>2610</td><td>1.074188</td><td>5.7019</td><td>3507.58</td><td>27.535</td></tr><tr><td>1.0908</td><td>4.296513</td><td>0.000181</td><td>2.00115</td><td>3480</td><td>1.047315</td><td>5.6973</td><td>3510.434</td><td>27.557</td></tr><tr><td>1.0226</td><td>3.782547</td><td>0.000171</td><td>2.501438</td><td>4350</td><td>1.043286</td><td>5.6781</td><td>3522.284</td><td>27.65</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.6759</td><td>4.424142</td><td>0.000029</td><td>7.504313</td><td>13050</td><td>1.135734</td><td>5.6571</td><td>3535.363</td><td>27.753</td></tr><tr><td>0.6799</td><td>3.291351</td><td>0.000019</td><td>8.0046</td><td>13920</td><td>1.118866</td><td>5.6781</td><td>3522.313</td><td>27.65</td></tr><tr><td>0.6419</td><td>3.996638</td><td>0.000011</td><td>8.504888</td><td>14790</td><td>1.145908</td><td>5.6604</td><td>3533.313</td><td>27.737</td></tr><tr><td>0.6386</td><td>4.407036</td><td>0.000005</td><td>9.005175</td><td>15660</td><td>1.145411</td><td>5.6848</td><td>3518.16</td><td>27.618</td></tr><tr><td>0.6219</td><td>3.801413</td><td>0.000001</td><td>9.505463</td><td>16530</td><td>1.15306</td><td>5.6721</td><td>3526.056</td><td>27.68</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (19, 9)\n",
       "┌────────┬───────────┬────────────┬──────────┬───┬───────────┬────────────┬────────────┬───────────┐\n",
       "│ loss   ┆ grad_norm ┆ learning_r ┆ epoch    ┆ … ┆ eval_loss ┆ eval_runti ┆ eval_sampl ┆ eval_step │\n",
       "│ ---    ┆ ---       ┆ ate        ┆ ---      ┆   ┆ ---       ┆ me         ┆ es_per_sec ┆ s_per_sec │\n",
       "│ f64    ┆ f64       ┆ ---        ┆ f64      ┆   ┆ f64       ┆ ---        ┆ ond        ┆ ond       │\n",
       "│        ┆           ┆ f64        ┆          ┆   ┆           ┆ f64        ┆ ---        ┆ ---       │\n",
       "│        ┆           ┆            ┆          ┆   ┆           ┆            ┆ f64        ┆ f64       │\n",
       "╞════════╪═══════════╪════════════╪══════════╪═══╪═══════════╪════════════╪════════════╪═══════════╡\n",
       "│ 1.5113 ┆ 10.823572 ┆ 0.000199   ┆ 0.500288 ┆ … ┆ 1.173166  ┆ 5.6989     ┆ 3509.442   ┆ 27.549    │\n",
       "│ 1.1608 ┆ 3.601487  ┆ 0.000195   ┆ 1.000575 ┆ … ┆ 1.088658  ┆ 5.673      ┆ 3525.466   ┆ 27.675    │\n",
       "│ 1.0907 ┆ 2.74441   ┆ 0.000189   ┆ 1.500863 ┆ … ┆ 1.074188  ┆ 5.7019     ┆ 3507.58    ┆ 27.535    │\n",
       "│ 1.0908 ┆ 4.296513  ┆ 0.000181   ┆ 2.00115  ┆ … ┆ 1.047315  ┆ 5.6973     ┆ 3510.434   ┆ 27.557    │\n",
       "│ 1.0226 ┆ 3.782547  ┆ 0.000171   ┆ 2.501438 ┆ … ┆ 1.043286  ┆ 5.6781     ┆ 3522.284   ┆ 27.65     │\n",
       "│ …      ┆ …         ┆ …          ┆ …        ┆ … ┆ …         ┆ …          ┆ …          ┆ …         │\n",
       "│ 0.6759 ┆ 4.424142  ┆ 0.000029   ┆ 7.504313 ┆ … ┆ 1.135734  ┆ 5.6571     ┆ 3535.363   ┆ 27.753    │\n",
       "│ 0.6799 ┆ 3.291351  ┆ 0.000019   ┆ 8.0046   ┆ … ┆ 1.118866  ┆ 5.6781     ┆ 3522.313   ┆ 27.65     │\n",
       "│ 0.6419 ┆ 3.996638  ┆ 0.000011   ┆ 8.504888 ┆ … ┆ 1.145908  ┆ 5.6604     ┆ 3533.313   ┆ 27.737    │\n",
       "│ 0.6386 ┆ 4.407036  ┆ 0.000005   ┆ 9.005175 ┆ … ┆ 1.145411  ┆ 5.6848     ┆ 3518.16    ┆ 27.618    │\n",
       "│ 0.6219 ┆ 3.801413  ┆ 0.000001   ┆ 9.505463 ┆ … ┆ 1.15306   ┆ 5.6721     ┆ 3526.056   ┆ 27.68     │\n",
       "└────────┴───────────┴────────────┴──────────┴───┴───────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_consolidated = []\n",
    "i = 0\n",
    "while i < len(logs)-1:\n",
    "    base_log = logs[i]\n",
    "    base_log.update(logs[i+1])\n",
    "    logs_consolidated.append(base_log)\n",
    "    i += 2\n",
    "    \n",
    "df_logs = pl.DataFrame(logs_consolidated).sort(\"epoch\")\n",
    "df_logs.write_parquet(\"llm_scratch_train_logs.parquet\")\n",
    "df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import save_model\n",
    "\n",
    "save_model(model, \"imdb_embeddings_llm_scratch.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "\n",
    "In this case, need to evaluate the LLM in batches to avoid going OOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20_000, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Predicted</th><th>Actual</th><th>abs_diff</th><th>square_error</th></tr><tr><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>7.066406</td><td>7.1</td><td>0.033594</td><td>0.001129</td></tr><tr><td>6.2890625</td><td>6.5</td><td>0.2109375</td><td>0.044495</td></tr><tr><td>6.214844</td><td>4.1</td><td>2.114844</td><td>4.472565</td></tr><tr><td>5.214844</td><td>5.5</td><td>0.285156</td><td>0.081314</td></tr><tr><td>7.707031</td><td>7.2</td><td>0.507031</td><td>0.257081</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>6.6953125</td><td>6.2</td><td>0.495313</td><td>0.245335</td></tr><tr><td>4.644531</td><td>3.2</td><td>1.444531</td><td>2.08667</td></tr><tr><td>6.472656</td><td>5.7</td><td>0.772656</td><td>0.596998</td></tr><tr><td>6.09375</td><td>5.7</td><td>0.39375</td><td>0.155039</td></tr><tr><td>5.472656</td><td>5.8</td><td>0.327344</td><td>0.107154</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20_000, 4)\n",
       "┌───────────┬────────┬───────────┬──────────────┐\n",
       "│ Predicted ┆ Actual ┆ abs_diff  ┆ square_error │\n",
       "│ ---       ┆ ---    ┆ ---       ┆ ---          │\n",
       "│ f32       ┆ f32    ┆ f32       ┆ f32          │\n",
       "╞═══════════╪════════╪═══════════╪══════════════╡\n",
       "│ 7.066406  ┆ 7.1    ┆ 0.033594  ┆ 0.001129     │\n",
       "│ 6.2890625 ┆ 6.5    ┆ 0.2109375 ┆ 0.044495     │\n",
       "│ 6.214844  ┆ 4.1    ┆ 2.114844  ┆ 4.472565     │\n",
       "│ 5.214844  ┆ 5.5    ┆ 0.285156  ┆ 0.081314     │\n",
       "│ 7.707031  ┆ 7.2    ┆ 0.507031  ┆ 0.257081     │\n",
       "│ …         ┆ …      ┆ …         ┆ …            │\n",
       "│ 6.6953125 ┆ 6.2    ┆ 0.495313  ┆ 0.245335     │\n",
       "│ 4.644531  ┆ 3.2    ┆ 1.444531  ┆ 2.08667      │\n",
       "│ 6.472656  ┆ 5.7    ┆ 0.772656  ┆ 0.596998     │\n",
       "│ 6.09375   ┆ 5.7    ┆ 0.39375   ┆ 0.155039     │\n",
       "│ 5.472656  ┆ 5.8    ┆ 0.327344  ┆ 0.107154     │\n",
       "└───────────┴────────┴───────────┴──────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "_ = model.to(\"cuda:0\").eval()  # to disable BatchNorm1D\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=False)\n",
    "preds_bucket = []\n",
    "\n",
    "for batch in tqdm(dataloader, smoothing=0):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=batch[0],\n",
    "                       attention_mask=batch[1])\n",
    "        preds = output.detach().cpu().numpy()\n",
    "\n",
    "    preds_bucket.append(preds)\n",
    "        \n",
    "actual_values = torch.stack([f[2] for f in test_dataset])\n",
    "\n",
    "test_results = (pl.DataFrame({\"Predicted\": np.hstack(preds_bucket), \"Actual\": actual_values.cpu().numpy()})\n",
    "                .with_columns(\n",
    "                    abs_diff=(pl.col(\"Predicted\") - pl.col(\"Actual\")).abs(),\n",
    "                    square_error = ((pl.col(\"Actual\") - pl.col(\"Predicted\")) ** 2)\n",
    "                )\n",
    "               )\n",
    "                \n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016399429321289"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "test_results[\"abs_diff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1549042394775857"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Square Error (MSE)\n",
    "test_results[\"square_error\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu123.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu123:m129"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
