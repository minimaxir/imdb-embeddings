{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Training\n",
    "\n",
    "Uses the Trainer included in Hugging Face `transformers` (backed by `accelerate`) since it mitigates a lot of annoying boilerplate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwoolf/Library/Mobile Documents/com~apple~CloudDocs/PythonProjects/imdb-embeddings/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tconst</th><th>averageRating</th><th>embedding</th></tr><tr><td>str</td><td>f32</td><td>array[f32, 768]</td></tr></thead><tbody><tr><td>&quot;tt0000009&quot;</td><td>5.4</td><td>[-0.007815, -0.022642, … 0.005391]</td></tr><tr><td>&quot;tt0000147&quot;</td><td>5.3</td><td>[0.012021, 0.014255, … -0.015754]</td></tr><tr><td>&quot;tt0000574&quot;</td><td>6.0</td><td>[-0.010052, -0.015825, … 0.040161]</td></tr><tr><td>&quot;tt0000591&quot;</td><td>5.6</td><td>[0.00765, 0.019661, … -0.010763]</td></tr><tr><td>&quot;tt0000630&quot;</td><td>3.2</td><td>[0.03492, 0.00301, … 0.027586]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;tt0035474&quot;</td><td>6.9</td><td>[0.007757, -0.011224, … 0.038445]</td></tr><tr><td>&quot;tt0035475&quot;</td><td>6.6</td><td>[0.005858, 0.008654, … 0.039309]</td></tr><tr><td>&quot;tt0035477&quot;</td><td>6.0</td><td>[0.007687, -0.020819, … 0.040466]</td></tr><tr><td>&quot;tt0035479&quot;</td><td>5.4</td><td>[0.03527, 0.018015, … 0.024018]</td></tr><tr><td>&quot;tt0035480&quot;</td><td>5.6</td><td>[0.010964, -0.009064, … 0.011847]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 3)\n",
       "┌───────────┬───────────────┬─────────────────────────────────┐\n",
       "│ tconst    ┆ averageRating ┆ embedding                       │\n",
       "│ ---       ┆ ---           ┆ ---                             │\n",
       "│ str       ┆ f32           ┆ array[f32, 768]                 │\n",
       "╞═══════════╪═══════════════╪═════════════════════════════════╡\n",
       "│ tt0000009 ┆ 5.4           ┆ [-0.007815, -0.022642, … 0.005… │\n",
       "│ tt0000147 ┆ 5.3           ┆ [0.012021, 0.014255, … -0.0157… │\n",
       "│ tt0000574 ┆ 6.0           ┆ [-0.010052, -0.015825, … 0.040… │\n",
       "│ tt0000591 ┆ 5.6           ┆ [0.00765, 0.019661, … -0.01076… │\n",
       "│ tt0000630 ┆ 3.2           ┆ [0.03492, 0.00301, … 0.027586]  │\n",
       "│ …         ┆ …             ┆ …                               │\n",
       "│ tt0035474 ┆ 6.9           ┆ [0.007757, -0.011224, … 0.0384… │\n",
       "│ tt0035475 ┆ 6.6           ┆ [0.005858, 0.008654, … 0.03930… │\n",
       "│ tt0035477 ┆ 6.0           ┆ [0.007687, -0.020819, … 0.0404… │\n",
       "│ tt0035479 ┆ 5.4           ┆ [0.03527, 0.018015, … 0.024018… │\n",
       "│ tt0035480 ┆ 5.6           ┆ [0.010964, -0.009064, … 0.0118… │\n",
       "└───────────┴───────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    pl.scan_parquet(\n",
    "        \"/Users/maxwoolf/Downloads/movie_data_plus_embeds_all.parquet\", n_rows=10000\n",
    "    )\n",
    "    .select([\"tconst\", \"averageRating\", \"embedding\"])\n",
    "    .with_columns(averageRating=pl.col(\"averageRating\").cast(pl.Float32))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "tensor_embeddings = torch.from_numpy(df[\"embedding\"].to_numpy().copy()).to(device)\n",
    "tensor_ratings = torch.from_numpy(df[\"averageRating\"].to_numpy().copy()).to(device)\n",
    "\n",
    "tensor_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tensor_embeddings, tensor_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(768, 1536)\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(1536)\n",
    "        self.linear_2 = nn.Linear(1536, 768)\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(768)\n",
    "        self.linear_3 = nn.Linear(768, 256)\n",
    "        self.batchnorm_3 = nn.BatchNorm1d(256)\n",
    "        self.output = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.linear_1(x))\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = F.gelu(self.linear_2(x))\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = F.gelu(self.linear_3(x))\n",
    "        x = self.batchnorm_3(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x.squeeze()  # return 1D output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RatingsModel(\n",
       "  (linear_1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "  (batchnorm_1): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear_2): Linear(in_features=1536, out_features=768, bias=True)\n",
       "  (batchnorm_2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear_3): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (batchnorm_3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RatingsModel()\n",
    "_ = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    inputs = torch.stack([f[0] for f in examples])\n",
    "    outputs = torch.stack([f[1] for f in examples])\n",
    "\n",
    "    return (inputs, outputs)\n",
    "\n",
    "\n",
    "class MAETrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch):\n",
    "        preds = model(inputs[0])\n",
    "        loss = nn.L1Loss()(preds, inputs[1])  # L1 loss is MAE\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-2,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    per_device_train_batch_size=128,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.001,\n",
    "    save_strategy=\"no\",\n",
    "    eval_strategy=\"no\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=0.1,\n",
    "    fp16=False,\n",
    "    dataloader_num_workers=0,  # since data is in memory\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_persistent_workers=False,\n",
    ")\n",
    "\n",
    "# reinstantiate a clean model\n",
    "model = RatingsModel()\n",
    "_ = model.to(device)\n",
    "\n",
    "trainer = MAETrainer(\n",
    "    model, training_args, train_dataset=train_dataset, data_collator=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='790' max='790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [790/790 00:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.623300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.577700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>0.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>0.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>632</td>\n",
       "      <td>0.536300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>0.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.506100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=790, training_loss=0.7061055243769778, metrics={'train_runtime': 5.8204, 'train_samples_per_second': 17181.038, 'train_steps_per_second': 135.73, 'total_flos': 0.0, 'train_loss': 0.7061055243769778, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
